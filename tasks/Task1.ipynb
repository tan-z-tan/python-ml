{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 簡単な分類問題 iris\n",
    "\n",
    "植物の「あやめ」の種類を花の大きさ（4変数）から推定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import Image \n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを読み込む\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# データを見てみる\n",
    "print(\"Iris Data\")\n",
    "df = pd.DataFrame(iris.data)\n",
    "df['target'] = iris.target\n",
    "print(\"data = \", iris.feature_names)\n",
    "print(\"target = \", iris.target_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをプロットしてみる\n",
    "\n",
    "plt.clf()\n",
    "f, axarr = plt.subplots(2, 2, sharex='col', sharey='row', figsize=(11, 10))\n",
    "\n",
    "axarr[0, 0].scatter(iris.data[:, 0], iris.data[:, 1], c=iris.target, alpha=0.6)\n",
    "axarr[0, 0].set_title(iris.feature_names[0] + \" vs \" + iris.feature_names[1])\n",
    "\n",
    "axarr[0, 1].scatter(iris.data[:, 1], iris.data[:, 2], c=iris.target, alpha=0.6)\n",
    "axarr[0, 1].set_title(iris.feature_names[1] + \" vs \" + iris.feature_names[2])\n",
    "\n",
    "axarr[1, 0].scatter(iris.data[:, 0], iris.data[:, 3], c=iris.target, alpha=0.6)\n",
    "axarr[1, 0].set_title(iris.feature_names[0] + \" vs \" + iris.feature_names[3])\n",
    "\n",
    "axarr[1, 1].scatter(iris.data[:, 2], iris.data[:, 3], c=iris.target, alpha=0.6)\n",
    "axarr[1, 1].set_title(iris.feature_names[2] + \" vs \" + iris.feature_names[3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn準拠の識別器を作る\n",
    "- BaseEstimator\n",
    "- ClassifierMixin\n",
    "\n",
    "必要なメソッドだけ定義すると他のsk-learnの識別機と同じように使える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class IrisClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        return self \n",
    "    \n",
    "    def predict_proba(self, x_list):\n",
    "        return [self.predict_proba_sample(x) for x in x_list]\n",
    "\n",
    "    def predict(self, x_list):\n",
    "        proba = self.predict_proba(x_list)\n",
    "        most_probable_category = np.argmax(proba, axis=1)\n",
    "        return most_probable_category\n",
    "\n",
    "    def predict_proba_sample(self, x):\n",
    "        # e.g.  x = [5.1\t3.5\t1.4\t0.2] should be classified as 0 ([1, 0, 0])\n",
    "\n",
    "        FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 精度の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "## 評価\n",
    "### 単純化のために2次元の特徴量のみを使う\n",
    "X = iris.data[:, [0, 1]]\n",
    "y = iris.target\n",
    "\n",
    "clf = IrisClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# 予測する\n",
    "predicted = clf.predict(X)\n",
    "\n",
    "# 精度(accuracy)\n",
    "print(\"Accuracy = \", clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 世の中の機械学習モデルをいくつか試す\n",
    "- SVM\n",
    "- DicisionTree\n",
    "- KNN\n",
    "- 自作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単純化のために2次元の特徴量のみを使う\n",
    "X = iris.data[:, [0, 1]]\n",
    "y = iris.target\n",
    "\n",
    "#　識別器のインスタンスをつくる. SVM\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "# 学習させる\n",
    "svm.fit(X, y)\n",
    "\n",
    "# 学習データに対する精度\n",
    "print(\"Score = {0}\".format(svm.score(X, y)))\n",
    "\n",
    "# 最初の10個を予測する\n",
    "for x in X[:10]:\n",
    "    print(\"Predict f(%s) = %s\" % (x, svm.predict([x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 他の識別器\n",
    "classifiers = [\n",
    "    SVC(kernel='rbf', probability=True),\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    KNeighborsClassifier(n_neighbors=1),\n",
    "    IrisClassifier(),\n",
    "    ]\n",
    "\n",
    "# 同じインタフェース で使える\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X, y)\n",
    "\n",
    "# Plotting decision regions\n",
    "plt.clf()\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05), np.arange(y_min, y_max, 0.05))\n",
    "\n",
    "f, axarr = plt.subplots(2, 2, sharex='col', sharey='row', figsize=(11, 10))\n",
    "\n",
    "for index, classifier, title in zip([0, 1, 2, 3], classifiers, ['Kernel SVM', 'Decision Tree (depth=2)', 'KNN (k=1)', 'IrisClassifer']):\n",
    "    predicted = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    predicted = predicted.reshape(xx.shape)\n",
    "    \n",
    "    #     print(predicted)\n",
    "    axarr[index // 2, index % 2].contourf(xx, yy, predicted, alpha=0.3)\n",
    "    axarr[index // 2, index % 2].scatter(X[:, 0], X[:, 1], c=y, alpha=0.6)\n",
    "    axarr[index // 2, index % 2].set_title(\"%s (%f)\" % (title, classifier.score(X, y)))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "予測したものと正解の数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(y, ｃｌｆ.predict(X))\n",
    "plot_confusion_matrix(matrix, ['A', 'B', 'C'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## クロスバリデーション\n",
    "for classifier, title in zip(classifiers, ['Decision Tree (depth=2)', 'KNN (k=1)', 'Kernel SVM', 'Iris Classifier']):\n",
    "    scores = cross_val_score(classifier, X, y, cv=6)\n",
    "    print(\"Cross Validation Score of %s\" % title)\n",
    "    print(\"mean(%s) = %s\" % (scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グリッドサーチで最適なパラーメタを探す\n",
    "ref. http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## パラメータのグリッドサーチ\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search_params = [{\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1],\n",
    "    FILL HERE\n",
    "}]\n",
    "\n",
    "tuned_clf = GridSearchCV(DecisionTreeClassifier(random_state=1), search_params, cv=6)\n",
    "tuned_clf.fit(iris.data, iris.target)\n",
    "print(\"Best Score %s \" % tuned_clf.best_score_)\n",
    "print(\"Best Params %s \" % tuned_clf.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
